import os
import pandas as pd
import re
from workalendar.asia import Taiwan  # ä½¿ç”¨ workalendar è¨ˆç®—å°ç£çš„å·¥ä½œæ—¥
import csv
from datetime import timedelta

# å‰µå»ºè¼¸å‡ºè³‡æ–™å¤¾åç¨±
output_dir = "auction_data_processed"
os.makedirs(output_dir, exist_ok=True)

# è®€å– cleaned_auction_data.csv æª”æ¡ˆ
cleaned_auction_data_path = "cleaned_auction_data.csv"
auction_data = pd.read_csv(cleaned_auction_data_path, encoding='utf-8')

# 1. å‹•æ…‹æ“·å– DateStart å’Œ DateEnd ä¹‹é–“çš„æ¬„ä½ï¼Œä¸¦æ¨™è¨˜åç§»é‡
columns = auction_data.columns.tolist()
start_index = columns.index("DateStart")
end_index = columns.index("DateEnd")


date_columns_raw = columns[start_index:end_index + 1]

# ä¿®æ­£ï¼šæ­£ç¢ºè¾¨è­˜åç§»æ ¼å¼ï¼Œä¸¦æª¢æŸ¥åŸºç¤æ¬„ä½æ˜¯å¦å­˜åœ¨
date_columns = {}
for col in date_columns_raw:
    match = re.match(r"(.+?)([+-]\d+)$", col.strip())
    
    if match:
        base_name = match.group(1).strip()
        offset = int(match.group(2))
        
        # æª¢æŸ¥åŸºç¤æ¬„ä½æ˜¯å¦å­˜åœ¨æ–¼è³‡æ–™ä¸­
        if base_name in auction_data.columns:
            date_columns[col] = {'base': base_name, 'offset': offset}
        else:
            # è‹¥åŸºç¤æ¬„ä½ä¸å­˜åœ¨ï¼Œè¦–ç‚ºå®Œæ•´æ¬„ä½åç¨±ï¼Œç„¡åç§»
            date_columns[col] = {'base': col, 'offset': 0}
    else:
        date_columns[col] = {'base': col, 'offset': 0}
print(date_columns,"<<AAAAAAAAAAAAAAA")


# ç²å–æ‰€æœ‰æ–‡ä»¶åˆ—è¡¨
all_files = [f for f in os.listdir('stockdata') if f.endswith('.csv')]

# åˆå§‹åŒ–å°ç£å·¥ä½œæ—¥è¨ˆç®—
cal = Taiwan()

# è®€å– holidays.csvï¼Œä¸¦è™•ç†æ ¼å¼
holidays_path = "holidays.csv"
if os.path.exists(holidays_path):
    try:
        holidays_list = []
        with open(holidays_path, "r", encoding="utf-8") as file:
            reader = csv.reader(file)
            for row in reader:
                date_part = row[0].strip() if len(row) > 0 else None
                if date_part:
                    holidays_list.append(date_part)

        holidays = pd.DataFrame(holidays_list, columns=["æ—¥æœŸ"])
        holidays["æ—¥æœŸ"] = holidays["æ—¥æœŸ"].str.extract(r"(\d{4}-\d{2}-\d{2})", expand=False)
        holidays["æ—¥æœŸ"] = pd.to_datetime(holidays["æ—¥æœŸ"], errors="coerce").dt.date
        holidays_set = set(holidays["æ—¥æœŸ"].dropna())

        print(f"æˆåŠŸè®€å– holidays.csvï¼Œå…± {len(holidays_set)} å€‹å‡æ—¥")
    except Exception as e:
        print(f"è®€å– holidays.csv æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        holidays_set = set()
else:
    print("æ‰¾ä¸åˆ° holidays.csvï¼Œå°‡ä¸è€ƒæ…®å‡æ—¥")
    holidays_set = set()


# 2. å®šç¾©å‡½æ•¸ä»¥ç²å–æ”¶ç›¤åƒ¹ï¼Œä¸¦æ ¹æ“šåç§»é‡èª¿æ•´
def get_closing_price(security_id, base_date, offset=0):
    """
    æ ¹æ“šè­‰åˆ¸ä»£è™Ÿå’Œæ—¥æœŸç²å–æ”¶ç›¤åƒ¹ï¼Œä¸¦æ ¹æ“šåç§»é‡èª¿æ•´æ—¥æœŸï¼ˆéç´¢å¼•ä½ç½®ï¼‰ã€‚
    """
    for file_name in all_files:
        if file_name.startswith(f"[{security_id}]") and file_name.endswith(".csv"):
            try:
                # Update file path to use stockdata directory
                full_path = os.path.join('stockdata', file_name)
                price_data = pd.read_csv(full_path, encoding='utf-8')
                price_data['æ—¥æœŸ'] = pd.to_datetime(price_data['æ—¥æœŸ'], errors='coerce').dt.date
                price_data = price_data.sort_values(by='æ—¥æœŸ').reset_index(drop=True)

                # Convert base_date to datetime object
                base_date_dt = pd.to_datetime(base_date, errors='coerce')
                if pd.isna(base_date_dt):
                    print(f"ç„¡æ•ˆæ—¥æœŸæ ¼å¼: base_date={base_date}, offset={offset}")
                    return ""
                
                # Calculate the target date by adding offset days to base_date
                from datetime import timedelta
                base_date = base_date_dt.date()
                target_date = base_date + timedelta(days=offset)
                
                # CHANGED: Added holiday check in addition to weekend check
                is_weekend = target_date.weekday() >= 5
                is_holiday = target_date in holidays_set  # NEW
                is_non_trading_day = is_weekend or is_holiday  # NEW
                
                # Look for the target date in the data
                target_data = price_data[price_data['æ—¥æœŸ'] == target_date]
                
                if not target_data.empty:
                    # Target date found
                    return target_data.iloc[0]['æ”¶ç›¤åƒ¹']
                else:
                    # CHANGED: Only print if it's a regular trading day (not weekend or holiday)
                    if not is_non_trading_day:  # CHANGED from "if not is_weekend:"

                        # Check if this date should exist (is it within the file's date range?)
                        min_date = price_data['æ—¥æœŸ'].min()
                        max_date = price_data['æ—¥æœŸ'].max()
                        if min_date <= target_date <= max_date:
                            print(f"  ğŸˆ³ç¯„åœå…§ï¼Œä½†æ²’æœ‰æ•¸æ“š: target_date={target_date} (base_date={base_date}, offset={offset}), æª”æ¡ˆ={file_name} æ³¨æ„: æ­¤æ—¥æœŸåœ¨æª”æ¡ˆæ—¥æœŸç¯„åœå…§ ({min_date} è‡³ {max_date})ï¼Œä½†æ²’æœ‰æ•¸æ“š (å¯èƒ½æ˜¯éé æœŸçš„ä¼‘å¸‚æ—¥)")
                        else:
                            print(f"  ğŸš€æœªä¾†æ—¥æœŸ: target_date={target_date} (base_date={base_date}, offset={offset}), æª”æ¡ˆ={file_name} æ³¨æ„: æœªä¾†æ—¥æœŸï¼Œç„¡æ³•ç²å–æ•¸æ“š")
                    # NEW: Optional debugging for weekend/holiday identification
                    elif is_weekend:
                        # Optional: You can uncomment if you want weekend prints
                        print(f"  ğŸ›Œé€±æœ«éäº¤æ˜“æ—¥: target_date={target_date} (base_date={base_date}, offset={offset})")
                        pass
                    elif is_holiday:
                        # Optional: You can uncomment if you want holiday prints
                        print(f"  ğŸ§¨å‡æ—¥éäº¤æ˜“æ—¥: target_date={target_date} (base_date={base_date}, offset={offset})")
                        pass
                    return ""
                
            except (KeyError, FileNotFoundError, pd.errors.EmptyDataError) as e:
                print(f"è™•ç†æª”æ¡ˆæ™‚å‡ºéŒ¯: {file_name}, éŒ¯èª¤: {e}")
                continue
    
    # CHANGED: Updated the check for non-trading days at end of function
    from datetime import timedelta
    target_date = base_date + timedelta(days=offset)
    is_weekend = target_date.weekday() >= 5
    is_holiday = target_date in holidays_set  # NEW
    is_non_trading_day = is_weekend or is_holiday  # NEW
    
    if not is_non_trading_day:  # CHANGED from "if target_date.weekday() < 5:"
        print(f"ç„¡è³‡æ–™: security_id={security_id}, target_date={target_date} (base_date={base_date}, offset={offset})")
    return ""

# 3. è¨ˆç®—è³‡æ–™ç¸½æ•¸èˆ‡ç¸½å·¥ä½œå¤©æ•¸
def get_security_stats(security_id):
    """
    è¨ˆç®—è³‡æ–™ç¸½æ•¸èˆ‡ç¸½å·¥ä½œå¤©æ•¸
    """
    for file_name in all_files:
        if file_name.startswith(f"[{security_id}]") and file_name.endswith(".csv"):
            try:
                # Update file path to use stockdata directory
                full_path = os.path.join('stockdata', file_name)
                price_data = pd.read_csv(full_path, encoding='utf-8')

                total_rows = price_data.shape[0]
                price_data['æ—¥æœŸ'] = pd.to_datetime(price_data['æ—¥æœŸ'], errors='coerce').dt.date

                match = re.search(r"\[(\d+)\] (\d{4}-\d{2}-\d{2})-(\d{4}-\d{2}-\d{2})", file_name)
                if match:
                    start_date = pd.to_datetime(match.group(2), errors='coerce').date()
                    end_date = pd.to_datetime(match.group(3), errors='coerce').date()

                    if start_date and end_date:
                        working_days = 0
                        current_date = start_date
                        while current_date <= end_date:
                            if not cal.is_holiday(current_date) and current_date not in holidays_set and cal.is_working_day(current_date):
                                working_days += 1
                            current_date += timedelta(days=1)

                        print(f"è‚¡ç¥¨ä»£è™Ÿ: {security_id}, è³‡æ–™ç¸½æ•¸: {total_rows}/ç¸½å·¥ä½œå¤©æ•¸: {working_days}")
                        return total_rows, working_days
                    else:
                        return total_rows, "ç„¡è³‡æ–™"
                else:
                    return total_rows, "ç„¡è³‡æ–™"

            except (FileNotFoundError, pd.errors.EmptyDataError) as e:
                print(f"è®€å–è­‰åˆ¸æª”æ¡ˆéŒ¯èª¤: {e}")
                return "ç„¡è³‡æ–™", "ç„¡è³‡æ–™"
    return "ç„¡è³‡æ–™", "ç„¡è³‡æ–™"


# 4. æ›´æ–°è³‡æ–™ä¸­çš„æ—¥æœŸæ¬„ä½ä¸¦æ·»åŠ æ–°åˆ—
auction_data.insert(auction_data.columns.get_loc("DateEnd") + 1, "è³‡æ–™ç¸½æ•¸", "ç„¡è³‡æ–™")
auction_data.insert(auction_data.columns.get_loc("è³‡æ–™ç¸½æ•¸") + 1, "ç¸½å·¥ä½œå¤©æ•¸", "ç„¡è³‡æ–™")

for index, row in auction_data.iterrows():
    security_id = row["è‚¡ç¥¨ä»£è™Ÿ"]

    # æ›´æ–°æ—¥æœŸæ¬„ä½ï¼Œæ ¹æ“šåç§»é‡èª¿æ•´æ”¶ç›¤åƒ¹æŸ¥è©¢
    for col, info in date_columns.items():
        base_col = info['base']
        offset = info['offset']

        if base_col in auction_data.columns and pd.notna(row[base_col]):
            closing_price = get_closing_price(security_id, row[base_col], offset)
            auction_data.at[index, col] = closing_price
        else:
            auction_data.at[index, col] = "ç„¡è³‡æ–™"


    
    # ç²å–è³‡æ–™ç¸½æ•¸å’Œç¸½å·¥ä½œå¤©æ•¸
    total_rows, working_days = get_security_stats(security_id)
    auction_data.at[index, "è³‡æ–™ç¸½æ•¸"] = total_rows
    auction_data.at[index, "ç¸½å·¥ä½œå¤©æ•¸"] = working_days

# 5. å„²å­˜æ›´æ–°çš„è³‡æ–™è‡³æ–°çš„æª”æ¡ˆä¸­
output_path = os.path.join(output_dir, "updated_cleaned_auction_data.csv")
auction_data.to_csv(output_path, index=False, encoding='utf-8-sig')

print(f"å·²å®Œæˆè³‡æ–™è™•ç†ä¸¦å„²å­˜è‡³ {output_path}")
